\section{PDF-independent storage of phase-space weights with PineAPPL}
\label{sec:pineappl}

In this section we introduce \textsc{PineAPPL}.
We first describe the general scope and features of the library in comparison to \textsc{APPLgrid} and \textsc{fastNLO} in section~\ref{sec:library}.
Section~\ref{sec:multi-coupling-expansion} gives the details and, in particular, describes the problem of computing Monte Carlo weights for cross sections in a multi-coupling expansion; this section may be read first by readers unfamiliar with the programs mentioned previously.
In section~\ref{sec:perturbative-orders} we discuss a few properties of multi-coupling-expanded predictions.

\subsection{The PineAPPL library}
\label{sec:library}

\textsc{PineAPPL} is a new library which stores phase-space weights of a Monte Carlo (MC) integration of a fixed-order calculation independently from the chosen PDFs.
The task of computing predictions for physical observables is therefore split
into two steps: 1) the generation of the \emph{grids}, i.e.\ the files in
which the MC weights are stored, and 2) the convolution of these grids with a set of PDFs.
The advantage of this method is that the time-consuming step 1) has to be performed only once, and that step 2) is reduced to a fast convolution of a given grid with one (or more) PDF set(s).

The convolution is typically done in few seconds or less, a fact that offers at least two applications:
\begin{enumerate}
\item the study of the PDF-dependence of the observables; e.g.\ PDF set comparisons, PDF uncertainty computations, $\alphas$ variations, etc., and
\item the determination of PDF sets themselves; together with the corresponding experimental data, the grids constitute two important ingredients for a PDF fit.
\end{enumerate}
These features are common to both \textsc{PineAPPL} and \textsc{APPLgrid}~\cite{Carli:2010rw} or \textsc{FastNLO}~\cite{Kluge:2006xs,Wobisch:2011ij,Britzger:2012bs}. However, in comparison to the last two pieces of code,
\textsc{PineAPPL} allows one to include also higher-order corrections due to EW, and in general combined QCD--EW, effects for the first time.
Documenting this extension, and how to interface \textsc{PineAPPL} with a general-purpose matrix-element generator, is the main goal of this paper.

In particular, \textsc{PineAPPL} supports the following features.
\begin{itemize}
\item The inclusion of perturbative corrections (fixed-order, i.e.\ without parton-shower matching) with any given set of powers of $\alpha$, $\alphas$, in particular including combined QCD--EW corrections.
\item The support for non-coloured initial-state partons, such as photon-initiated contributions, and, more generally, arbitrary initial-state combinations, e.g.\ leptonic initial states~\cite{Bertone:2015lqa,Buonocore:2020nai}.
\item The estimate of theory uncertainties via variations of the renormalisation and factorisation scale (the electroweak coupling is assumed to be scale-independent, consistently with the most common renormalisation schemes).
\end{itemize}
On a more technical level, we point out the following additional features of \textsc{PineAPPL}.

\begin{itemize}

\item \textsc{PineAPPL} comes with the shell command \texttt{pineappl}, which performs convolutions on the command line, without requiring the user to write a new program.
In addition to convolutions, the shell command can also print how the luminosity function is constructed, which perturbative orders are stored in the grids, their size, the size of each partonic channel, etc., separately for each bin. See appendix~\ref{app:pineappl-demo} for details.
  
\item \textsc{PineAPPL} offers an easy-to-use interface written in the C programming language, that allows MC integrators to read and write \textsc{PineAPPL} grids.
C was chosen because it can be easily interfaced with both Fortran and C++, the two main programming languages in which most MC integrators are written.
The interface consists of roughly thirty functions, among which only a handful are needed in practice.
We also provide and support a Python package based on this C interface.
See appendix~\ref{app:example-program} for an example.

\item \textsc{PineAPPL} has been explicitly interfaced to \textsc{mg5\_aMC} (v3+)~\cite{Alwall:2014hca,Frederix:2018nkq},\footnote{A version of \textsc{mg5\_aMC} interfaced to \textsc{PineAPPL} can be downloaded from \url{https://launchpad.net/mg5amc-pineappl/trunk}, and it will be included as standard starting from the 3.0.4 release of \textsc{mg5\_aMC}.} see appendix~\ref{app:sample-runcard} for an example of a runcard.
The usage of \textsc{mg5\_aMC}(v3+) + \textsc{PineAPPL} is similar to that of \textsc{mg5\_aMC}(v2) + \textsc{aMCfast} + \textsc{APPLgrid}.
While the latter toolchain proved to be sufficiently efficient for NLO QCD calculations of typical kinematic distributions (with a few bins), this is no longer so when taking into account NLO EW calculations and, with more precise data, distributions that are typically more complex and have more bins.
Taking into account these two reasons, we find that the memory usage of \textsc{APPLgrid} is no longer satisfiable.
In particular, using \textsc{APPLgrid} for NLO QCD+EW\footnote{For this a modified version of \textsc{APPLgrid} was developed which added support for photon-initiated processes and EW corrections.} typically requires close to \SI{120}{\giga\byte} for high-mass Drell--Yan with 13 bins (see section~\ref{sec:dy-lepton-pair-production}).
The memory usage is substantially reduced to roughly \SI{1}{\giga\byte} after \enquote{optimisation} of the grids, i.e.\ an optimisation of the grid representation in memory.
However, this requires a two-step procedure: first, to produce an unoptimised grid in order to identify those parts where the cross section is either zero or extremely suppressed; second, after those parts are removed, to fill an optimised grid with a small number of bins.
\textsc{PineAPPL} avoids this by using a more space-efficient representation from the start. This leads to substantially faster run times, in particular for simple processes, because the grids do not need to be optimised 
and their combination is faster.

%\item Possibility to import \textsc{APPLgrids} and \textsc{fastNLO} tables.
\end{itemize}


\subsection{Cross sections in a multi-coupling expansion}
\label{sec:multi-coupling-expansion}

Fixed-order partonic cross sections $a + b \to X$ supported by \textsc{PineAPPL} are written as an expansion in powers of the strong coupling $\alphas$, the electromagnetic coupling $\alpha$, and the logarithms of $\xi_\mathrm{R} = \mu_\mathrm{R} / Q$ and $\xi_\mathrm{F} = \mu_\mathrm{F} / Q$,
\begin{multline}
\frac{\mathrm{d} \sigma_{ab}}{\mathrm{d} \mathcal{O}} (x_1, x_2, \mathcal{O}, \xi_\mathrm{R}, \xi_\mathrm{F}) \\
= \sum_{k,l,m,n} \alphas^k \left( \xi_\mathrm{R}^2 Q^2 \right) \alpha^l \log^m ( \xi_\mathrm{R}^2 ) \log^n ( \xi_\mathrm{F}^2 ) W_{ab}^{(k,l,m,n)} \left( x_1, x_2, Q^2, \mathcal{O} \right) \text{.}
\label{eq:expansion}
\end{multline}
This cross section is differential with respect to the observable $\mathcal{O}$, which, in general, is a function of phase space and subject to the usual conditions (soft and collinear safety, etc.).

In experiments, but also for many calculations where the phase-space integration is performed using MC techniques, finite statistics does not allow for the exact reconstruction of the dependence of the cross section on the observable $\mathcal{O}$.
Instead, it is sufficient to approximate the derivative using a piecewise-constant function,
\begin{equation}
W_{ab}^{(k,l,m,n)} \left( x_1, x_2, Q^2, \mathcal{O} \right) \approx \sum_{o=1}^M \frac{\Theta (\mathcal{O}_o^\mathrm{min} \le \mathcal{O} < \mathcal{O}_o^\mathrm{max})}{\mathcal{O}_o^\mathrm{max} - \mathcal{O}_o^\mathrm{min}} w_{ab}^{(k,l,m,n,o)} \left( x_1, x_2, Q^2 \right) \text{,}
\label{eq:differential-cross-section}
\end{equation}
which uses $M$ bins with limits $\{ \mathcal{O}_o^\mathrm{min}, \mathcal{O}_o^\mathrm{max} \}_{o=1}^M$ to partition a finite range of the observable,
\begin{equation}
\mathcal{O}_0^\mathrm{min} < \mathcal{O}_0^\mathrm{max} = \mathcal{O}_1^\mathrm{min} < \ldots < \mathcal{O}_{M-1}^\mathrm{max} = \mathcal{O}_M^\mathrm{min} < \mathcal{O}_M^\mathrm{max} \text{.}
\label{eq:bins-of-diff-xsection}
\end{equation}
The Ellis--Sexton scale $Q^2$, if chosen dynamically, depends on the phase space, however we assume the fractions $\xi_\mathrm{R}$ and $\xi_\mathrm{F}$ to be  phase-space constants in any case.
This allows for variations around the central scale choice $\xi_\mathrm{R} = \xi_\mathrm{F} = 1$, but it does not otherwise allow for arbitrary changes of the scale.
The terms with powers $m > 0$ and $n > 0$ vanish for the central scale choice and are only required for variations of the factorisation and renormalisation scales.
To estimate the perturbative QCD uncertainty --- no EW uncertainty is covered by this method --- one typically uses scale variations. Common prescriptions are
7-point and 9-points scale variations, which evaluate the cross section using
respectively the following values
  \begin{align}
    (\xi_\mathrm{R}, \xi_\mathrm{F})_{\mathrm{7-pt}}
    & \in
    \left\{ \bigl( 1, 1 \bigr), \bigl( \tfrac{1}{2}, \tfrac{1}{2} \bigr), \bigl( 2, 2 \bigr), \bigl( \tfrac{1}{2}, 1 \bigr), \bigl( 1, \tfrac{1}{2} \bigr), \bigl( 2, 1 \bigr), \bigl( 1, 2 \bigr) \right\} \text{;}
    \label{eq:7pt}\\
    (\xi_\mathrm{R}, \xi_\mathrm{F})_{\mathrm{9-pt}}
    & \in
    \left\{ \bigl( 1, 1 \bigr), \bigl( \tfrac{1}{2}, \tfrac{1}{2} \bigr), \bigl( 2, 2 \bigr), \bigl( \tfrac{1}{2}, 1 \bigr), \bigl( 1, \tfrac{1}{2} \bigr), \bigl( 2, 1 \bigr), \bigl( 1, 2 \bigr), \bigl( \tfrac{1}{2}, 2 \bigr), \bigl(2, \tfrac{1}{2} \bigr) \right\}  \text{.}
    \label{eq:9pt}
   \end{align}
The (asymmetric) uncertainties are then given as the minimum and maximum value (the envelope), measured from the central value $(1, 1)$.
As is clear from eq.~\eqref{eq:expansion}, the EW coupling $\alpha$ is assumed not to be a dynamically varying coupling, but instead a constant over phase space.
This, however, includes the most common choices of the coupling, which are (not necessarily in this order), $\alpha (0)$, $\alpha (M_\mathrm{Z})$, and $\alpha_{G_\mu}$.

The problem that \textsc{PineAPPL} solves can now be described: approximately reconstruct the functions
\begin{equation}
w_{ab}^{(k,l,m,n,o)} \left( x_1, x_2, Q^2 \right)
\label{eq:weight-map}
\end{equation}
of eq.~\eqref{eq:differential-cross-section} from a set of $N$ function evaluations for specific momentum fractions, scales, and values of the observable
\begin{equation}
\left\{ x_1^{(i)}, x_2^{(i)}, Q^2_i, \mathcal{O}_i \right\}_{i=1}^N \text{,} \label{eq:phase-space-weights}
\end{equation}
given by the MC integrator together with the corresponding value of the weights, eq.~\eqref{eq:weight-map}.
This problem is solved by finding an appropriate representation of eq.~\eqref{eq:phase-space-weights} and is described in section~\ref{sec:grid-representation}.
Using eq.~\eqref{eq:expansion} and
\begin{multline}
\frac{\mathrm{d} \sigma}{\mathrm{d} \mathcal{O}} (\mathcal{O}, \xi_\mathrm{R}, \xi_\mathrm{F}) \\
= \sum_{a,b} \int_0^1 \mathrm{d} x_1 \int_0^1 \mathrm{d} x_2 \int_{Q^2_\mathrm{min}}^{Q^2_\mathrm{max}} \mathrm{d} Q^2 \, f_a (x_1, \xi_\mathrm{F}^2 Q^2) f_b (x_2, \xi_\mathrm{F}^2 Q^2) \sigma_{ab} (x_1, x_2, Q^2, \xi_\mathrm{R}, \xi_\mathrm{F}) \text{,}
\label{eq:pineappl-convolution}
\end{multline}
\textsc{PineAPPL} can then quickly calculate hadronic cross sections for an arbitrary number of PDF sets and perform scale variations.

Note that we have omitted the dependence of the weights $w$, the observable $\mathcal{O}$, and the scales $\mu_\mathrm{F}, \mu_\mathrm{R}, Q^2$ on the specific kinematics for which they are computed.
Indeed, beyond LO, different kinematic contributions have to be considered (in ref.~\cite{Bertone:2014zva}, for example, they are labelled with an index $\alpha$, see eq.~(12) therein).
In the FKS subtraction scheme~\cite{Frixione:1995ms,Frixione:1997np} employed in \textsc{mg5\_aMC} one type of kinematics for each counterterm (soft, collinear, and soft-collinear) is needed, however this is not the general case.
In Catani--Seymour subtraction~\cite{Catani:1996jh,Catani:2002hc}, for example, different dipoles have different phase spaces and therefore different scales.
\textsc{PineAPPL} remains completely blind to this fact, and a consistent treatment is ensured by filling each event into a grid using the \emph{numerical value} of $Q^2$.

\subsubsection{Grid representations}
\label{sec:grid-representation}

We now explain the details of how the phase-space weights $w_{ab}$ in eq.~\eqref{eq:bins-of-diff-xsection} are represented.

\paragraph{4-tuples.}
A straightforward representation is given by 4-tuples, i.e.\ a list of the momentum fractions $x_1$ and $x_2$, the scale $Q^2$, and the phase-space weight $w$ for each phase-space point; 4-tuples are sufficient to reconstruct the differential cross sections.
For each combination $(a,b,k,l,m,n,o)$ (see section~\ref{sec:multi-coupling-expansion} for their definition) we save the following 4-tuples,
\begin{equation}
\left\{ x_1^i, x_2^i, Q^2_i, w^{(k,l,m,n,o)}_{ab} (x_1^i, x_2^i, Q^2_i, \mathcal{O}_i) \right\}_{i=1}^N \text{.} \label{eq:four-tuples}
\end{equation}
The reconstruction of the differential cross sections are then done by simply multiplying the phase-space weights $w$ with PDFs evaluated with the correct arguments given in the 4-tuple and summing over all indices $a$, $b$, $k$, $l$, $m$, $n$, $o$, and $i$.

The 4-tuple representation is very easy to implement and test.
Furthermore, it reproduces the exact numerical value that is also calculated by the MC integrator.
However, the price one has to pay is the size of the 4-tuples.
For example, NLO QCD+EW Drell--Yan lepton-pair production (see section~\ref{sec:pineappl-example} and section~\ref{sec:dy-lepton-pair-production}) needs \SI{159}{\mega\byte} of storage for a target precision of \SI{1}{\percent} of the integrated cross section.
While this is an acceptable size, increasing the precision by an order of magnitude would require roughly 100 times the size, due to the Monte Carlo convergence that goes as $1/\sqrt{N}$ with $N$ being the number of 4-tuples.
With increasing size also the speed of the convolution degrades, because it basically becomes bound by the speed with which the 4-tuples can be read from disk.
However, due to the uncompressed nature of this representation it can serve as an intermediate format to develop and quickly cross check more space-efficient representations, one of which we will discuss next.

\paragraph{Lagrange-interpolation grid.}
A different strategy is to partition a subset $H$ of the $(x_1, x_2, Q^2)$ space,
\begin{equation}
H = [x_\mathrm{min},x_\mathrm{max}]^2 \times [Q^2_\mathrm{min}, Q^2_\mathrm{max}] \ni (x_1, x_2, Q^2)
\end{equation}
along each axis into a small number of bins and to insert the phase-space weights $w$ into the corresponding discrete bin.
Using the bin centres and their values one already has a straightforward representation of eq.~\eqref{eq:weight-map}, but given a finite number of bins this approach usually yields an insufficient approximation for the cross section.
Increasing the number of bins improves the precision, but it also increases the space requirements.
This problem in turn is solved using interpolation methods, which increase the precision using the same number of bins.

We use the \enquote{Lagrange-interpolation grid} method presented in ref.~\cite{Carli:2010rw} with the parameters published in ref.~\cite{Bertone:2014zva}, which give sufficient precision (see section~\ref{sec:results}).
For the sake of completeness, the following summarises the interpolation algorithm.

This method first maps $(x_1, x_2, Q^2) \mapsto (y_1, y_2, \tau)$, with
\begin{equation}
y(x) = 5 (1-x) - \log x \text{,} \qquad \tau (Q^2) = \log \log \frac{Q^2}{(\SI{0.25}{\giga\electronvolt})^2} \text{.}
\label{eq:maps}
\end{equation}
The function $y(x)$ maps events with large $x$ effectively linearly and small $x$ effectively logarithmically onto $y$.
This reflects our knowledge of PDFs, which behave differently in those two regions, and thereby increases the precision of the interpolation.
For the convolution of a grid with a PDF set also the inverse functions are needed, which are
\begin{equation}
x(y) = \frac{1}{5} \operatorname{W}_0 (5 \exp (5-y)) \text{,} \qquad Q^2 (\tau) = (\SI{0.25}{\giga\electronvolt})^2 \exp (\exp (\tau)) \text{,}
\end{equation}
where $\operatorname{W}_0 (x)$ is (the principle branch of) the Lambert W function or product logarithm, which satisfies the relation $\operatorname{W} (x) \exp (\operatorname{W} (x)) = x$.

Following ref.~\cite{Carli:2010rw} (see eq.~(17) therein), we furthermore divide the weights, before filling them into the grid, by the function
\begin{equation}
\omega (x_1, x_2) = \left( \frac{\sqrt{x_1}}{1 - 0.99 x_1} \right)^3 \left( \frac{\sqrt{x_2}}{1 - 0.99 x_2} \right)^3 \text{.}
\end{equation}
This flattens the interpolated function in the region $x \to 1$, where the PDFs are small and tend towards zero, and enhances the function in the small-$x$ region.
The effect of this step is an improvement of the precision that depends on the initial states and the process, but it can be as large as a factor of \numrange{10}{100} (one or two more correct digits compared to the MC result).
Before performing a convolution this step is inverted by simply multiplying the interpolated grid values with $\omega (x_1, x_2)$.

The final step is filling the weights into the grid, which maps the variables $(y_1, y_2, \tau)$ onto the 3-dimensional Lagrange-interpolation grid with $N_y = 50$ points in each $y$ direction and $N_\tau = 30$ points in the $\tau$ direction.
The interpolation orders $s_y$ and $s_\tau$ are 3 for each dimension, and only the subspace $[\num{2e-7},1] \times [\num{2e-7},1] \times [\num{e2},\num{e6}] \subset H$\footnote{In ref.~\cite{Bertone:2014zva} the upper limit for $Q$ is given as \SI{3162}{\giga\electronvolt} (which corresponds to $Q_\mathrm{max}^2 \approx \SI{e7}{\giga\electronvolt}$), but in the code we found the value $Q_\mathrm{max}^2 = \SI{e6}{\giga\electronvolt\squared}$.} is mapped.

\begin{figure}[!t]
\centering
\parbox{0.6\textwidth}{\includegraphics{figures/grid-insertion}}
\begin{tabular}{ll}
\toprule
$u_1$/$u_2$ & $x_1$/$x_2$ \\
\midrule
0 & \num{1.00e0} \\
1 & \num{6.36e-1} \\
2 & \num{3.20e-1} \\
3 & \num{9.96e-2} \\
4 & \num{1.57e-2} \\
5 & \num{1.74e-3} \\
6 & \num{1.81e-4} \\
7 & \num{1.87e-5} \\
8 & \num{1.93e-6} \\
9 & \num{2.00e-7} \\
\bottomrule
\end{tabular}
\caption{Example of a 2-dimensional $10 \times 10$ grid, which is being filled at the location marked with the small black square at $(5.8,4.8)$.
Each side of the grey square starting at $k_i = 4$ and $k_j = 3$ has a length of $N_y + 1 = 4$.
This square marks the grid values (grey dots) that are being updated using eq.~\eqref{eq:interpolation}.
The table on the right-hand side gives the parton-momentum fractions for each grid point according to eq.~\eqref{eq:maps}.
Note that for $u \in [0, 3]$ the values are roughly linearly distributed, then logarithmically.}
\label{fig:grid}
\end{figure}

To illustrate the filling step we give an example in figure~\ref{fig:grid}, where, for simplicity, we have chosen a static scale, so that we do not need to interpolate in the $\tau$ direction, and where we also limited the number of grid points to $N_y = 10$.
Each grid point has a numerical value $a_{i,j}$ associated, and the set of all numerical values $\{ a_{i,j} \}$ for all grid indices $(i,j) \in [0,N_y) \times [0,N_y)$ constitute \enquote{the grid}.
Inserting a specific weight $W = w (x_1, x_2) / \omega(x_1, x_2)$ into the grid is shown in figure~\ref{fig:grid} as a small black square, inside the larger grey one.
We have defined the grid points at specific positions, but the points given by the MC will land somewhere between them.
The interpolation order $s_y$ then defines a square with length $s_y + 1$ around its centre $(u(y(x_1)),u(y(x_2)))$, given by the MC\@.
All grid points with indices $(i,j)$ covered by the grey square are then updated according to the following formula,
\begin{equation}
a_{i,j} \leftarrow a_{i,j} + I_i(u(y(x_1))) I_j(u(y(x_2))) W(x_1,x_2) / \omega(x_1,x_2) \text{,}
\label{eq:interpolation}
\end{equation}
with the Lagrange basis functions,
\begin{equation}
I_i (u) = \prod_{\substack{k=k_i \\ k \neq i}}^{k_i + s_y} \frac{u-k}{i-k} \text{,}
\end{equation}
where the product runs over all indices of the grid points covered by the grey square in figure~\ref{fig:grid}, starting from the smallest index in the square, $k_i$ and $k_j$.
Finally, we remap
\begin{equation}
u(y) = \frac{y-y_\text{min}}{\Delta y} \text{,} \quad
\end{equation}
using $y_\text{min} = y(x_\text{max})$ and $y_\text{max} = y(x_\text{min})$ and the grid spacing $\Delta y = (y_\text{max} - y_\text{min})/(N_y-1)$, so that the integer part of $u(y)$ gives the grid point index, e.g.\ $u(y_\text{min}) = 0$ and $u(y_\text{max}) = N_y - 1$, and the fractional part of $u(y)$ gives the relative location between the nearest grid points.

\subsection{Perturbative orders}
\label{sec:perturbative-orders}

In section~\ref{sec:multi-coupling-expansion} we labelled the different perturbative orders using the indices $k,l,m,n$; their values are process specific.
However, in general we define as leading order (LO) the set of contributions for all possible initial states $a b$ that lead to the same final state $X$, for which the sum of the coupling exponents in eq.~\eqref{eq:expansion} is smallest, i.e.\ $k + l = p$, where $p = \min (k+l)$.
This number is usually determined by the number of external particles.
For many processes there is only one contribution at LO (in terms of $k$ and $l$), but this is not true in general. Indeed, when a process has multiple quark lines, colourless (photons, \dots) and coloured particles (gluons, \ldots) can be exchanged between them, making it possible to have more than one combination of $\alphas$ and $\alpha$.
A typical example at the LHC is (on-shell) top-pair production, which has three different contributions at LO: $\mathcal{O} (\alpha^2)$, $\mathcal{O} (\alphas \alpha)$, and $\mathcal{O} (\alpha^2)$.
Each contribution receives a higher-order correction with an additional power of $\alphas$ or $\alpha$, which in general leads to at least two next-to-leading order (NLO) corrections.
The correction with the largest power in $\alphas$ can be unambiguously called \enquote{the} QCD correction, and the one with the largest power in $\alpha$ \enquote{the} EW correction.
All remaining corrections are of combined type, meaning that, in general, they cannot be attributed to either one of strong or electroweak origin. However, for the sake of simplicity and with a slight abuse of notation, it is customary to call
NLO QCD (EW) corrections those
corrections of order $\alphas$ ($\alpha$) times the couplings of the LO contribution 
with the largest power of $\alphas$. In the example above, NLO QCD and EW corrections to top pair production will denote
respectively those at $\mathcal{O} (\alphas^3 )$ and $\mathcal{O} (\alphas^2 \alpha)$. In this paper, in particular
when discussing results in sec.~\ref{sec:results}, we will explicitly list the orders that are considered in the cross
section at LO, NLO QCD and NLO QCD+EW accuracy.

Due to the typical sizes of the couplings $\alphas^2 \sim \alpha$, it is naively expected that within the same order, i.e.\ for fixed $k + l$, terms with larger powers $\alphas^k$ dominate over those with smaller powers (and larger powers of $\alpha^l$).
In practice, however, this naive expectation is not always true due to dynamic effects.
Some examples are vector-boson scattering processes~\cite{Biedermann:2017bss,Denner:2019tmn}, top-pair production with a W boson and four-top production~\cite{Frederix:2017wme}, and Higgs production with a bottom-pair~\cite{Pagani:2020rsg}.

\subsubsection{Example: Drell--Yan lepton-pair production at the LHC}
\label{sec:pineappl-example}

To give an example of eq.~\eqref{eq:expansion}, the following shows Drell--Yan lepton-pair production up to terms at NLO (with some arguments suppressed for the phase-space weights):
\begin{equation}
\begin{split}
\sigma_{ab}
    &= \alpha^2 W_{ab}^{(0,2,0,0)} \\
    &+ \alphas \left( \xi_\mathrm{R}^2 Q^2 \right) \alpha^2 W_{ab}^{(1,2,0,0)} (Q^2) + \alphas \left( \xi_\mathrm{R}^2 Q^2 \right) \log (\xi_\mathrm{F}^2) \alpha^2 W_{ab}^{(1,2,0,1)} \\
    &+ \alpha^3 W_{ab}^{(0,3,0,0)} (Q^2) + \log (\xi_\mathrm{F}^2) \alpha^3 W_{ab}^{(0,3,0,1)} \text{.}
\end{split}
\end{equation}
The term in the first line is the LO term, the second line shows the NLO QCD correction, and the third line the NLO EW correction.
Note that all terms depend on the renormalisation scale only indirectly through $\alphas$, because 1) higher-order terms in $\alpha$ never generate a renormalisation scale dependence (in the $\alpha$ schemes that are valid according to section~\ref{sec:multi-coupling-expansion}) and 2) higher-order QCD corrections only introduce an explicit renormalisation scale dependence in counterterms with vertices with more than two gluons.
At NLO these terms are not present for this process so that terms proportional to $\log (\xi_\mathrm{R}^2)$ vanish.
Both NLOs, however, have contributions from a collinear counterterm that depends on the factorisation scale.
Since this process has a single LO, combined QCD--EW corrections first appear at next-to-next-to-leading order (NNLO), which include the QCD correction at $\mathcal{O} (\alphas^2 \alpha^2)$, the EW correction $\mathcal{O} (\alpha^4)$, and a single combined correction at $\mathcal{O} (\alphas \alpha^3)$.

Note that all initial states have to be taken into account that lead to the same final state.
This includes the photon--photon initial state, which appears already at LO\@.
In the corresponding Feynman diagrams all particles are colourless, so that the photon--photon initiated contributions only receive EW corrections.
The EW corrections also introduce quark--photon contributions, in analogy of QCD corrections introducing quark--gluon contributions.
